{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pan/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/envs/pan/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/opt/conda/envs/pan/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[36mModelZipper is ready for launchüöÄ | Current Versionü¶Ñ >>> 0.2.7 <<< | AOE Timeüïí 2024-05-08 13:19:42\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pan/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.61it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ËÆ©Ê®°ÂûãËæìÂá∫‰∏Ä‰∏™‰ΩéPPLÁöÑÂè•Â≠ê‰Ωú‰∏∫key\n",
    "ËÆ©Ê®°ÂûãËæìÂá∫‰∏Ä‰∏™È´òPPLÁöÑÂè•Â≠ê‰Ωú‰∏∫key\n",
    "\"\"\"\n",
    "\n",
    "from modelzipper.tutils import *\n",
    "import transformers\n",
    "import math\n",
    "import torch\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\"/vepfs/wcf/G/zecheng/hf_models/llama-2-7b-80k\").to('cuda:7')\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"/vepfs/wcf/G/zecheng/hf_models/llama-2-7b-80k\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoding results:\n",
      "<s> This is a passkey for the door to the basement of the house.\n",
      "This is the first time I've seen this. I don't know what it is. It's a little bit of a mystery. But I think it might be something to\n",
      "reversed decoding results:\n",
      "do. and see to things many so are There city. the around walk to is Francisco San in do to thing best The\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"\\nThe best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.\\n\"\n",
    "KEY, VALUE = \"\\nThe best thing to do in San Francisco is\", \"eat a sandwich and sit in Dolores Park on a sunny day.\\n\"\n",
    "KEY = \"This is a passkey\"\n",
    "num_sequence = 2\n",
    "\n",
    "input_ids = tokenizer(KEY, return_tensors='pt').input_ids.to(model.device)\n",
    "value_ids_len = tokenizer(VALUE, return_tensors='pt').input_ids.size(-1)\n",
    "candidates = model.generate(input_ids, num_beams=num_sequence, num_return_sequences=num_sequence, penalty_alpha=0.6, no_repeat_ngram_size=2, temperature=0.7, top_p=0.95, do_sample=True, min_new_tokens=value_ids_len, max_new_tokens=value_ids_len + 32, return_dict_in_generate=True, output_scores=True)\n",
    "\n",
    "sequences_scores = candidates['sequences_scores']\n",
    "outputs = candidates.sequences[0]\n",
    "\n",
    "output_str = tokenizer.decode(outputs)\n",
    "print(\"decoding results:\")\n",
    "print(output_str)\n",
    "\n",
    "new_needle = \"The best thing to do in San Francisco is to walk around the city. There are so many things to see and do.\"\n",
    "reverse_needle_str = \" \".join(new_needle.split()[::-1])\n",
    "print(\"reversed decoding results:\")\n",
    "print(reverse_needle_str)\n",
    "\n",
    "# for score, output in zip(sequences_scores, outputs):\n",
    "#     res = tokenizer.decode(output)\n",
    "#     print(f\"score: {math.exp(score)} | decode: {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.3507, device='cuda:7', grad_fn=<ExpBackward0>)\n",
      "tensor([[    1,  2058, 29889, 21863,   292,   445,   310, 10083,   322,   269,\n",
      "          5861,   278,   599,  1074,   304,  2221,   367,   674,   887,  4272,\n",
      "         29889,   278,  2820,  6686,   304,   338,  8970,  3087,   297,   437,\n",
      "           304,  2655,  1900,   450]], device='cuda:7')\n",
      "tensor(416.8795, device='cuda:7', grad_fn=<ExpBackward0>)\n",
      "tensor([[    1,  2058, 29889, 21863,   292,   445,   310, 10083,   322,   269,\n",
      "          5861,   278,   599,  1074,   304,  2221,   367,   674,   887,  4272,\n",
      "         29889,   278,  2820,  6686,   304,   338,  8970,  3087,   297,   437,\n",
      "           304,  2655,  1900,   450]], device='cuda:7')\n",
      "tensor(416.8795, device='cuda:7', grad_fn=<ExpBackward0>)\n",
      ". placeing amaz this of sounds andights s the all see to able be will You. city the around walk to is Francisco San in do to thing best The\n",
      "tensor(1476.7153, device='cuda:7', grad_fn=<ExpBackward0>)\n"
     ]
    }
   ],
   "source": [
    "new_needle = \"The best thing to do in San Francisco is to walk around the city. You will be able to see all the sights and sounds of this amazing place.\"\n",
    "tok_new_needle = tokenizer(new_needle, return_tensors='pt').input_ids.to(model.device)\n",
    "new_needle_ppl = torch.exp(model(tok_new_needle, labels=tok_new_needle).loss)\n",
    "print(new_needle_ppl)\n",
    "\n",
    "reverse_needle = \" \".join(new_needle.split(\" \")[::-1])\n",
    "reverse_new_needle = tokenizer(reverse_needle, return_tensors='pt').input_ids.to(model.device)\n",
    "reverse_needle_ppl = torch.exp(model(reverse_new_needle, labels=reverse_new_needle).loss)\n",
    "print(reverse_new_needle)\n",
    "print(reverse_needle_ppl)\n",
    "\n",
    "\n",
    "# ÂÅöindex level ÁöÑ reverse\n",
    "reverse_needle = \" \".join(new_needle.split(\" \")[::-1])\n",
    "reverse_new_needle = tokenizer(reverse_needle, return_tensors='pt').input_ids.to(model.device)\n",
    "reverse_needle_ppl = torch.exp(model(reverse_new_needle, labels=reverse_new_needle).loss)\n",
    "print(reverse_new_needle)\n",
    "print(reverse_needle_ppl)\n",
    "\n",
    "# ÂÅötoken ids ÁöÑ reverse\n",
    "flip_tok = torch.flip(tok_new_needle[:, 1:], dims=(1,))\n",
    "flip_needle_str = tokenizer.decode(flip_tok[0])\n",
    "flip_needle_ids = tokenizer(flip_needle_str, return_tensors='pt').input_ids.to(model.device)\n",
    "flip_needle_ppl = torch.exp(model(flip_needle_ids, labels=flip_needle_ids).loss)\n",
    "print(flip_needle_str)\n",
    "print(flip_needle_ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,   450,  1900,  2655,   304,   437,   297,  3087,  8970,   338,\n",
      "           304,  6686,  2820,   278,  4272, 29889,   887,   674,   367,  2221,\n",
      "           304,  1074,   599,   278,   269,  5861,   322, 10083,   310,   445,\n",
      "         21863,   292,  2058, 29889]], device='cuda:7')\n",
      ". placeing amaz this of sounds andights s the all see to able be will You. city the around walk to is Francisco San in do to thing best The\n"
     ]
    }
   ],
   "source": [
    "print(tok_new_needle)\n",
    "flip_tok = torch.flip(tok_new_needle[:, 1:], dims=(1,))\n",
    "flip_str = tokenizer.decode(flip_tok[0])\n",
    "print(flip_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
